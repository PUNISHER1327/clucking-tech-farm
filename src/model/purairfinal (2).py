# -*- coding: utf-8 -*-
"""PurairFinal

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wCpsn9JRYkF1LXlSJv9m2ajAnNoAaubL
"""

# ============================================
#        PURAIR — FUTURE-READY LSTM MODEL
#        Clean, Stable, Proper Time-Series
# ============================================

# ---- Imports ----
import numpy as np
import pandas as pd
import tensorflow as tf
import random
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ---- Reproducibility ----
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

# ============================================
#                LOAD DATA
# ============================================

df = pd.read_csv("purairDataset2.csv")
df["Timestamp"] = pd.to_datetime(df["Timestamp"], yearfirst=True)

# FEATURES AVAILABLE RIGHT NOW
features = ["AirQuality_MQ135", "Temperature", "Humidity"]

# ============================================
#      CLEAN DATA + SCALE SENSOR FEATURES
# ============================================

scaler_X = StandardScaler()
df_scaled = df.copy()
df_scaled[features] = scaler_X.fit_transform(df[features])

# ============================================
#            SEQUENCE GENERATOR
# ============================================

def create_sequences(df, feature_cols, target_col, window):
    X, y = [], []
    F = df[feature_cols].values
    T = df[target_col].values

    for i in range(window, len(df)):
        X.append(F[i-window:i])
        y.append(T[i])

    return np.array(X), np.array(y)

window = 30

X, y = create_sequences(df_scaled, features, "Egg_Count", window)

# ============================================
#                TRAIN-TEST SPLIT
# ============================================

split = int(0.8 * len(X))

X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# ---- Scale target y ----
scaler_y = StandardScaler()
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))
y_test_scaled  = scaler_y.transform(y_test.reshape(-1,1))

# ============================================
#             BUILD THE MODEL
# ============================================

n_features = len(features)

model = tf.keras.Sequential([
    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(window, n_features)),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.LSTM(64, return_sequences=False),
    tf.keras.layers.Dropout(0.2),

    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1)
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss="mse",
    metrics=["mae"]
)

# ============================================
#               TRAIN THE MODEL
# ============================================

es = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    patience=20,
    restore_best_weights=True
)

lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.2,
    patience=8,
    verbose=1
)

history = model.fit(
    X_train,
    y_train_scaled,
    validation_split=0.2,
    epochs=250,
    batch_size=16,
    shuffle=False,
    callbacks=[es, lr],
    verbose=1
)

# ============================================
#                PREDICTION
# ============================================

y_pred_scaled = model.predict(X_test).flatten()
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1)).flatten()

# ============================================
#                METRICS
# ============================================

MAE  = mean_absolute_error(y_test, y_pred)
MSE  = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)
R2   = r2_score(y_test, y_pred)

print("MAE:", MAE)
print("RMSE:", RMSE)
print("R²:", R2)

# ============================================
#              VISUALIZATION
# ============================================

plt.figure(figsize=(14,6))
plt.plot(y_test[:200], label="Actual", linewidth=2)
plt.plot(y_pred[:200], label="Predicted", linewidth=2)
plt.title("Improved Egg Count Prediction (Future-Ready LSTM)")
plt.legend()
plt.show()

# ============================================
#               SAVE ARTIFACTS
# ============================================

model.save("PURAIR_LSTM_v2.h5")
print("Model saved as PURAIR_LSTM_v2.h5")

import joblib
joblib.dump(scaler_X, "scaler_X.pkl")
joblib.dump(scaler_y, "scaler_y.pkl")

print("Scalers saved.")

"""**Predictions!**"""

# ============================================
#       PURAIR — MERGED PREDICTION PIPELINE
#        (All outputs → one single CSV)
# ============================================

import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import glob
import os

# --------------------------------------------
#             CONFIG
# --------------------------------------------

WINDOW = 30

# Model features expected
MODEL_FEATURES = ["AirQuality_MQ135", "Temperature", "Humidity"]

# Incoming CSV → Model mapping
CSV_TO_MODEL_MAP = {
    "air_quality": "AirQuality_MQ135",
    "temperature": "Temperature",
    "humidity": "Humidity"
}

# --------------------------------------------
#         LOAD MODEL + SCALERS
# --------------------------------------------

model = tf.keras.models.load_model(
    "PURAIR_LSTM_v2.h5",
    custom_objects={"mse": tf.keras.losses.MeanSquaredError()}
)

scaler_X = joblib.load("scaler_X.pkl")
scaler_y = joblib.load("scaler_y.pkl")

print("Model & scalers loaded successfully.")

# --------------------------------------------
#        CREATE SEQUENCES (for inference)
# --------------------------------------------

def create_sequences(df, feature_cols, window):
    X = []
    F = df[feature_cols].values

    for i in range(window, len(df)):
        X.append(F[i-window:i])

    return np.array(X)

# --------------------------------------------
#     PROCESS ALL SENSOR CSVs INTO ONE DF
# --------------------------------------------

input_files = [f for f in glob.glob("*.csv") if "predicted" not in f]
print("\nFound files:", input_files)

merged_output = []    # Store rows from all CSVs

for file in input_files:
    print(f"\nProcessing → {file}")

    df = pd.read_csv(file)

    # Rename for model
    df_renamed = df.rename(columns=CSV_TO_MODEL_MAP)

    # Ensure required columns exist
    for col in MODEL_FEATURES:
        if col not in df_renamed.columns:
            raise ValueError(f"Missing required column: {col} in {file}")

    # Scale
    df_scaled = df_renamed.copy()
    df_scaled[MODEL_FEATURES] = scaler_X.transform(df_renamed[MODEL_FEATURES])

    if len(df_scaled) < WINDOW:
        print("⚠️ Not enough rows, skipping:", file)
        continue

    # Create sequences
    X = create_sequences(df_scaled, MODEL_FEATURES, WINDOW)

    # Predict
    y_pred_scaled = model.predict(X).flatten()
    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(1, -1)).flatten()

    # Output DF (aligned rows)
    df_out = df.iloc[WINDOW:].copy()
    df_out["Predicted_Egg_Count"] = y_pred
    df_out["source_file"] = file

    merged_output.append(df_out)

# --------------------------------------------
# MERGE EVERYTHING AND SAVE FINAL CSV
# --------------------------------------------

if merged_output:
    final_df = pd.concat(merged_output, ignore_index=True)
    final_df.to_csv("PURAIR_All_Predictions.csv", index=False)
    print("\n✔ All predictions saved to → PURAIR_All_Predictions.csv")
else:
    print("\n⚠️ No valid predictions generated.")

# ============================================
#   PURAIR — STRICT SENSOR PREDICTION PIPELINE
# ============================================

import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import glob

WINDOW = 30

MODEL_FEATURES = ["AirQuality_MQ135", "Temperature", "Humidity"]

CSV_MAP = {
    "air_quality": "AirQuality_MQ135",
    "temperature": "Temperature",
    "humidity": "Humidity"
}

FINAL_COLS = [
    "id",
    "air_quality",
    "timestamp",
    "temperature",
    "humidity",
    "Predicted_Egg_Count",
    "source_file"
]

# Load model
model = tf.keras.models.load_model(
    "PURAIR_LSTM_v2.h5",
    custom_objects={"mse": tf.keras.losses.MeanSquaredError()}
)

scaler_X = joblib.load("scaler_X.pkl")
scaler_y = joblib.load("scaler_y.pkl")

def create_sequences(df, cols, window):
    X = []
    data = df[cols].values
    for i in range(window, len(df)):
        X.append(data[i-window:i])
    return np.array(X)

# ONLY RAW SENSOR FILES
files = glob.glob("sensor_data_rows-*.csv")

print("Processing ONLY sensor files:", files)

merged = []

for file in files:
    df = pd.read_csv(file)

    # Map to model format
    df_model = df.rename(columns=CSV_MAP)

    # Ensure correct order
    df_ordered = df_model[MODEL_FEATURES]

    # Scale
    scaled_vals = scaler_X.transform(df_ordered)
    df_scaled = df_model.copy()
    df_scaled[MODEL_FEATURES] = scaled_vals

    if len(df_scaled) < WINDOW:
        continue

    # Create sequences
    X = create_sequences(df_scaled, MODEL_FEATURES, WINDOW)

    # Predict
    y_scaled = model.predict(X).flatten()
    y_final = scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).flatten()

    # Output
    out = df.iloc[WINDOW:].copy()
    out["Predicted_Egg_Count"] = y_final
    out["source_file"] = file

    # Keep only valid columns
    out = out[FINAL_COLS]

    merged.append(out)

# Merge final data
final_df = pd.concat(merged, ignore_index=True)
final_df.to_csv("PURAIR_All_Predictions_CLEAN.csv", index=False)

print("✔ Clean merged file saved → PURAIR_All_Predictions_CLEAN.csv")